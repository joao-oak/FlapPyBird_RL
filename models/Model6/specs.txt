Reward function: collides = -10; outside of midrange = -5; cross pipe = +50

Network hyperparameters: 
learning_rate=5e-4, gamma=0.99, tau=0.01 ,epsilon_start=0.1, epsilon_min=0.0001, epsilon_decay=3000, batch_size=32, memory_size=10000
NO EPSILON, WAS SET TO DETERMINISTIC MODE WHERE THE ACTION IS ALWAYS RETRIEVED FROM THE NETWORK.

States:
player_height, player_y_velocity, next_pipe_distance_h, next_pipe_distance_v_l, next_pipe_distance_v_u, next_next_pipe_distance_h, next_next_pipe_distance_v_l, next_next_pipe_distance_v_u

Gradient clipping = 100

Update network at every step

Normalized input

Layer size = 64